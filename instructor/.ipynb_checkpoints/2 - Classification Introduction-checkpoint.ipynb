{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hour 2: Introduction to Classification:\n",
    "Python and Classification Labcamp - Milano, 25/05/2016\n",
    "\n",
    "Alex Loosley (a.loosley@reply.de)\n",
    "<br>Alex Salles (a.salles@reply.de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Classification:\n",
    "\n",
    "When an object can be **labeled** by a discrete class (*e.g.* dog or cat), the act of determining that class is called classification.\n",
    "\n",
    "## Iris Dataset:\n",
    "\n",
    "In the Pandas intro, we downloaded the IRIS dataset.  Exerpt [wikipedia](https://en.wikipedia.org/wiki/Iris_flower_data_set):\n",
    "\n",
    "<blockquote>\n",
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.[1] It is sometimes called Anderson's Iris datad set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species.[2] Two of the three species were collected in the Gaspé Peninsula \"all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus\".[3]\n",
    "</blockquote>\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/78/Petal-sepal.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Iris Dataset:\n",
    "\n",
    "<img src=\"../doc/ml_logo.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Algorithms:\n",
    "\n",
    "### Logistic Regression:\n",
    "Find straight lines that fit between two classes.  In a 3 class problem, find lines between *is_class* and *is_not_class* (*e.g.* iris-setosa vs. everything else, iris-versicolor vs. everything else, *etc.*)\n",
    "\n",
    "### Trees, Naive Bayes, SVM, Neural Networks, etc.\n",
    "![Picture from SKlearn](http://scikit-learn.org/stable/_images/plot_classifier_comparison_001.png)\n",
    "[Link to SKlearn classificaiton page](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)\n",
    "\n",
    "We'll implement a few of these below on the iris dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for Classificaton:\n",
    "\n",
    "There are a plethora of metrics for classification and they depend on whether the predictions are given in terms of the potential label classes or probabilities.\n",
    "\n",
    "## Metrics for Class Predictions:\n",
    "\n",
    "Let's start with the simplest.\n",
    "\n",
    "Recall this well-known table\n",
    "\n",
    "|                     | Observation Positive     | Observation Negative    |\n",
    "|---------------------|:------------------------:|:-----------------------:|\n",
    "| Prediction Positive |     True Positive        | False Positive (Type I) |\n",
    "| Prediction Negative | False Negative (Type II) |     True Negative       |\n",
    "\n",
    "There are many summary statistics one can compute from this table:\n",
    "1. The **Accuracy** gives the fraction labels correctly predicted (True Positives and True Negatives over everything).  \n",
    "1. The **Hamming Loss** gives the fraction of labels incorrectly predicted.  It is 1 - Accuracy.\n",
    "1. The **Precision** is true positives divided by all positive predictions: $p = \\frac{TP}{FP+TP}$\n",
    "1. The **Recall** is true positives divided by all positive observations: $r = \\frac{TP}{FN+TP}$\n",
    "1. There is also **F-beta** score: $F_\\beta=\\frac{(1+\\beta^2)\\cdot\\textrm{precission}\\cdot\\textrm{recall}}{\\beta^2 \\cdot\\textrm{precission}+\\textrm{recall}}$\n",
    "\n",
    "    This gives a weighted geometric average between the precision and recall (as a function of $\\beta$) and the **F-1** score is the special case when $\\beta = 1$.\n",
    "1. The **Jaccard Similarity Coefficient** is the True positives divided by the sum of true positives, false negatives, and false positives.  \n",
    "\n",
    "**Questions:**\n",
    "1. What's the interpretation of precision or recall? When would you want each?  \n",
    "1. Is Harvard's admission's process high precision or high recall? \n",
    "1. Should one optimize on recall or precission for an HIV-test?\n",
    "1. What about Sir Blackstone's aphorism \"Better that ten guilty persons escape than that one innocent suffer\" with Captain Louis Renault's order to \"Round up the Usual Suspects\" in the film \"Casablanca\"?\n",
    "\n",
    "MATERIAL ABOVE MODIFIED FROM MATERIAL I HAD FROM [THE DATA INCUBATOR](http://www.thedataincubator.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRIS Dataset Classification Example With Logistic Regression:\n",
    "Let's first grab the data and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = pd.DataFrame(iris.data[:, :2], columns=iris.feature_names[:2])  # we only take the first two features.\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X.iloc[:,0], X.iloc[:,1], c=y)\n",
    "plt.xlabel(X.columns[0])\n",
    "plt.ylabel(X.columns[1])\n",
    "plt.title('Three Class Example:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal:\n",
    "Classify flower type based on these two features: \n",
    "* sepal width\n",
    "* sepal length\n",
    "\n",
    "### Method:\n",
    "* Train Logistic Regression classifier based on data points givin (X,y)\n",
    "* Use Logistic Regression classifier to predict the flower type of a meshgrid of points spanning our feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "x_min, x_max = X.iloc[:, 0].min() - .5, X.iloc[:, 0].max() + .5\n",
    "y_min, y_max = X.iloc[:, 1].min() - .5, X.iloc[:, 1].max() + .5\n",
    "\n",
    "# Create a meshgrid of points:\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "X_predict = pd.DataFrame(np.c_[xx.ravel(), yy.ravel()], columns=iris.feature_names[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_predict.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ravel along with [np._c](https://docs.scipy.org/doc/numpy/reference/generated/numpy.c_.html) can be used to create an array of points from the meshgrid:\n",
    "* ravel flattens the matrix into an array\n",
    "* np._c zips the two points together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions within feature space and plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict = logreg.predict(X_predict)\n",
    "\n",
    "# Put the result into a color plot\n",
    "y_predict = y_predict.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.pcolormesh(xx, yy, y_predict, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.title('Flower Type Prediction Plot:')\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "- How well does our model perform? How do we measure it?\n",
    "\n",
    "- Why do we divide the model into training set and test set?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance-Bias Tradeoff\n",
    "\n",
    "The *Bias* corresponds to how far off we expect the model to deviate from reality (i.e. the model's bias) because of parametric assumptions (e.g. we forced the model to be linear or to be a tree of maximum depth 2).  It is given by the *In-Sample Error* of the above plot and always goes down with complexity.  High Bias models correspond to *underfitting*.\n",
    "\n",
    "The *Variance* accounts for the fact that the model was only trained on a (noisy) subset of the data and that the idiosyncratic noise in the data is therefore likely to contribute some variance to the model.  The more complex we allow the model to be, the more likely we are to overfit by picking up more of this noise.  High variance modesl correspond to *overfitting*.\n",
    "\n",
    "We can also think of bias as unmodelled data and variance as modelled noise.  As we increase the complexity of the model, we will necessarily model more of the data (reduce bais, reduce underfitting) but also start modelling noise (increase variance, increase overfitting).  Here's a helpful diagram of the decomposition.  Notice that at the optimal point, we have not yet learned on all our signal (still unmodelled data left) and we have picked up some noise and overfitting.\n",
    "\n",
    "![Bias-Variance from Dartmouth](../doc/bias-variance.png)\n",
    "\n",
    "(This section material from [The Data Incubator](http://www.thedataincubator.com), an prestigious data science training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- split the data set into training set and test set\n",
    "- train a Logistic Regression model with the traning set\n",
    "- predict the results of the test set\n",
    "- using the predicted values and the \"true\" values, create a confusion matrix\n",
    "- interpret the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optional:\n",
    "- repeat the exercise with diferent classifiers and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "logreg_validation = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "# train the model\n",
    "logreg_validation.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict the output\n",
    "y_predict = logreg_validation.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
